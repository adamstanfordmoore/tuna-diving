{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Analysis - The shape-based approach\n",
    "\n",
    "\n",
    "In this jupyter notebook, I am going to be building off of the Getting Started notebook by utlizing the following specifications that were derived in the notebook: \n",
    "\n",
    "1. dive threshold (meters): 30\n",
    "2. minimum dive length (number of measurements in the dive): 200\n",
    "3. number of principle components to take from the count-based representation: 10\n",
    "\n",
    "\n",
    "First, we are going to make a few crucial imports that will load all tag datasets, and get the dives that we want from them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utils\n",
    "import clusterUtils\n",
    "import tagStruct\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next cell, we are going to derive representations of the dives with the following specifications:\n",
    "1. pure counts\n",
    "2. take first 10 P.C.'s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/5111027PAM110P0574TS.csv\n",
      "['time', 'depth', 'temperature', 'light level']\n",
      "found:  time\n",
      "data/5111033PAM110P0587-Archive.csv\n",
      "['time', 'depth', 'temperature', 'light level']\n",
      "found:  time\n",
      "data/5111034PAM110P0588-Archive.csv\n",
      "['time', 'depth', 'temperature', 'light level']\n",
      "found:  time\n",
      "data/5111045PAM110P0590-Archive.csv\n",
      "['time', 'depth', 'temperature', 'light level']\n",
      "found:  time\n",
      "data/5112030PAM110P0416-Archive.csv\n",
      "['time', 'depth', 'temperature', 'light level']\n",
      "found:  time\n",
      "data/5112039PAM111P0762-Archive.csv\n",
      "['time', 'depth', 'temperature', 'light level']\n",
      "found:  time\n",
      "data/5112041PAM111P0763-Archive.csv\n",
      "['time', 'depth', 'temperature', 'light level']\n",
      "found:  time\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(clusterUtils)\n",
    "tags = utils.loadDatasets(threshold = 30 , truncationLength = 200)\n",
    "pureCounts10PCS = []\n",
    "for i in range(0, len(tags)):\n",
    "    pureCounts10PCS.append(utils.createRepresentation(tags[i], numComponents = 10, probability = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "allScores = [np.zeros((1, 30-2)) for i in range(0, len(pureCounts10PCS))]\n",
    "for i in range(0, 50):\n",
    "    siloScores = [clusterUtils.SC(pureCounts10PCS[i], \"cosine\", 30) for i in range(0, len(pureCounts10PCS))]\n",
    "    for j in range(0, len(siloScores)):\n",
    "        asNp = np.asarray(siloScores[j])\n",
    "        allScores[j] = allScores[j] + asNp\n",
    "allScores = [allScores[i]/(50) for i in range(0, len(allScores))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(allScores)):\n",
    "    siloScore = allScores[i][0]\n",
    "    plt.plot(range(1, len(siloScore)+1), siloScore)\n",
    "    plt.title(\"The maximum silhouette score was achieved at \" + str(np.argmax(np.asarray(siloScore))+1) + \" clusters.\")\n",
    "    plt.xlabel(\"Number of clusters\")\n",
    "    plt.ylabel(\"Silhouette Score\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quickly, let's look at how the number of principle components that we take from the dive representations affects the number of clusters that maximizes the silhouette score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pureCounts15PCS = []\n",
    "for i in range(0, len(tags)):\n",
    "    pureCounts15PCS.append(utils.createRepresentation(tags[i], numComponents = 20, probability = False))\n",
    "    \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "allScores15 = [np.zeros((1, 30-2)) for i in range(0, len(pureCounts15PCS))]\n",
    "for i in range(0, 50):\n",
    "    siloScores15 = [clusterUtils.SC(pureCounts15PCS[i], \"cosine\", 30) for i in range(0, len(pureCounts15PCS))]\n",
    "    for j in range(0, len(siloScores15)):\n",
    "        asNp = np.asarray(siloScores15[j])\n",
    "        allScores15[j] = allScores15[j] + asNp\n",
    "allScores15 = [allScores15[i]/(50) for i in range(0, len(allScores15))]\n",
    "\n",
    "\n",
    "for i in range(0, len(allScores)):\n",
    "    siloScore = allScores15[i][0]\n",
    "    print(np.argmax(np.asarray(siloScore))+1)\n",
    "    plt.plot(siloScore)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, after averaging the silhouette scores after 30 runs, it looks like there is a consistent cluster number that kmediods is settling on: 5-7 clusters! To analyze the clusters, we are going to do the following: \n",
    "\n",
    "\n",
    "1. Look at examples from each of the clusters. \n",
    "2. Map where the clusters are. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimalClusterNums = [5,5,7,6,7,7,7]\n",
    "import scipy.spatial.distance\n",
    "importlib.reload(clusterUtils)\n",
    "clusterAssignments = [clusterUtils.kMedoids(scipy.spatial.distance.squareform(\n",
    "            scipy.spatial.distance.pdist(pureCounts10PCS[i], metric = 'cosine')), optimalClusterNums[i])[1] for i in range(0, len(optimalClusterNums))]\n",
    "for i in range(0, len(clusterAssignments)):\n",
    "    listOfClustersExamples = clusterUtils.collectExampleFromClusterAssignments(clusterAssignments[i][1], tags[i])\n",
    "    clusterUtils.plotExamples(listOfClustersExamples, maxNumToPrint = 10)\n",
    "    print(\"______________________________________________________NEW TAG______________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(pureCounts10PCS)):\n",
    "    print(len(pureCounts10PCS[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterAssignmnets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(tagStruct)\n",
    "importlib.reload(clusterUtils)\n",
    "\n",
    "\n",
    "listyList = list()\n",
    "for i in range(0, len(tags)):\n",
    "    labelsVec = np.zeros((1, len(tags[i].dives)))\n",
    "    print(labelsVec.shape)\n",
    "    for k in range(0, (len(clusterAssignments[i])-1)):\n",
    "        divesInCluster = clusterAssignments[k]\n",
    "        for diveNummy in range(0, len(divesInCluster)):\n",
    "            xc = divesInCluster[diveNummy]\n",
    "            print(xc)\n",
    "            if xc < len(tags[i].dives):\n",
    "                labelsVec[0][xc] = k\n",
    "    listyList.append(labelsVec)\n",
    "    \n",
    "    \n",
    "    print(\"_________________\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.cluster\n",
    "optimalClusterNums = [5,5,7,6,7,7,7]\n",
    "for i in range(0, len(pureCounts10PCS)): ##each one of these things is a tag\n",
    "    k = optimalClusterNums[i]\n",
    "    kmeans =  sklearn.cluster.KMeans(n_clusters=k).fit(pureCounts10PCS[i])\n",
    "    labels = kmeans.labels_\n",
    "    f=open(tags[i].name + 'km.p',\"wb\")\n",
    "    pickle.dump(labels, f)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(tagStruct)\n",
    "importlib.reload(clusterUtils)\n",
    "for tag in tags: \n",
    "    clusterUtils.getDiveLocations(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probDissims = []\n",
    "for i in range(0, len(tags)):\n",
    "    probDissims.append(utils.createRepresentation(tags[i], numComponents = 0, probability = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siloScores2 = [clusterUtils.SC(probDissims[i], \"Jensen-Shannon\", 30) for i in range(0, len(probDissims))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(siloScores)):\n",
    "    siloScore = siloScores2[i]\n",
    "    plt.plot(siloScore)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(clusterUtils)\n",
    "BIC_AIC_tuples = [clusterUtils.GausMM(pureCounts10PCS[i], 30) for i in range(0, len(pureCounts10PCS))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(BIC_AIC_tuples)):\n",
    "    aic, bic = BIC_AIC_tuples[i]\n",
    "    averageAIC = np.sum(aic, axis=0)/aic.shape[0]\n",
    "    averageBIC = np.sum(bic, axis=0)/bic.shape[0]\n",
    "    plt.plot(averageAIC)\n",
    "    plt.plot(averageBIC)\n",
    "    print(np.argmax(averageAIC)+1)\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now I am going to look at how spectral clustering works for the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(clusterUtils)\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.cluster\n",
    "for i in range(0, len(pureCounts10PCS)): ##each one of these things is a tag\n",
    "    distanceMat = scipy.spatial.distance.squareform(\n",
    "            scipy.spatial.distance.pdist(pureCounts10PCS[i], metric = 'cosine'))\n",
    "    simMatrix = clusterUtils.simmMatrix(distanceMat, 1.0)\n",
    "    summed = np.zeros((1, 13))\n",
    "    for s in range(0, 50):\n",
    "        tempList= list()\n",
    "        for k in range(2, 15):\n",
    "            spec =  sklearn.cluster.SpectralClustering(n_clusters=k,\n",
    "             assign_labels=\"kmeans\",\n",
    "             random_state=0,\n",
    "            affinity = 'precomputed').fit(simMatrix)\n",
    "            silScore = metrics.silhouette_score(distanceMat, spec.labels_, metric=\"precomputed\", sampleSize = None)\n",
    "            tempList.append(silScore)\n",
    "        summed = summed + np.asarray(tempList)\n",
    "    summed[0] = summed[0] /50\n",
    "    plt.plot(range(1, len(summed[0])+1), summed[0], label = \"Spectral Clustering\")\n",
    "    siloScoreKMed = allScores[i][0][0:len(summed[0])]\n",
    "    plt.plot(range(1, len(summed[0])+1), siloScoreKMed, label = \"K-Medoids\")\n",
    "    plt.title(\"The maximum silhouette score was achieved at \" + str(np.argmax(np.asarray(summed[0]))+1) + \" clusters for spectral clustering.\")\n",
    "    plt.xlabel(\"Number of clusters\")\n",
    "    plt.ylabel(\"Silhouette Score\")\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So according to silhouette score, it looks like spectral clustering is giving us a superior clustering than k-mediods. Let's look at some example dives in each cluster assigned via silohouette score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "importlib.reload(clusterUtils)\n",
    "import pickle\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.cluster\n",
    "numClustersSpectClustering = [7,6,9,6,9,6,7]\n",
    "for i in range(0, len(pureCounts10PCS)): ##each one of these things is a tag\n",
    "    distanceMat = scipy.spatial.distance.squareform(\n",
    "            scipy.spatial.distance.pdist(pureCounts10PCS[i], metric = 'cosine'))\n",
    "    simMatrix = clusterUtils.simmMatrix(distanceMat, 1.0)\n",
    "    spec =  sklearn.cluster.SpectralClustering(n_clusters=numClustersSpectClustering[i],\n",
    "             assign_labels=\"kmeans\",\n",
    "             random_state=0,\n",
    "            affinity = 'precomputed').fit(simMatrix)\n",
    "    labels = spec.labels_\n",
    "    f=open(tags[i].name + 'Spectral.p',\"wb\")\n",
    "    pickle.dump(labels, f)\n",
    "    f.close()\n",
    "    reorderedLabels = clusterUtils.reorderInverse(labels)\n",
    "    listOfClustersExamples = clusterUtils.collectExampleFromClusterAssignments(reorderedLabels, tags[i])\n",
    "    clusterUtils.plotExamples(listOfClustersExamples, maxNumToPrint = 10)\n",
    "    print(\"______________________________________________________NEW TAG______________________________________________________\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how varying the principle components changes the silhoutte score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(clusterUtils)\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.cluster\n",
    "dimsToTry = [5,15, 20, 25, 50]\n",
    "for comp in dimsToTry:\n",
    "    pureCountsXPCS = []\n",
    "    for i in range(0, len(tags)):\n",
    "        pureCountsXPCS.append(utils.createRepresentation(tags[i], numComponents = comp, probability = False))\n",
    "        for i in range(0, len(pureCountsXPCS)): ##each one of these things is a tag\n",
    "            distanceMat = scipy.spatial.distance.squareform(\n",
    "                    scipy.spatial.distance.pdist(pureCountsXPCS[i], metric = 'cosine'))\n",
    "            simMatrix = clusterUtils.simmMatrix(distanceMat, 1.0)\n",
    "            summed = np.zeros((1, 13))\n",
    "            for s in range(0, 10):\n",
    "                tempList= list()\n",
    "                for k in range(2, 15):\n",
    "                    spec =  sklearn.cluster.SpectralClustering(n_clusters=k,\n",
    "                     assign_labels=\"kmeans\",\n",
    "                     random_state=0,\n",
    "                    affinity = 'precomputed').fit(simMatrix)\n",
    "                    silScore = metrics.silhouette_score(distanceMat, spec.labels_, metric=\"precomputed\", sampleSize = None)\n",
    "                    tempList.append(silScore)\n",
    "                summed = summed + np.asarray(tempList)\n",
    "            summed[0] = summed[0] /10\n",
    "            plt.plot(range(1, len(summed[0])+1), summed[0], label = \"Spectral Clustering\")\n",
    "            siloScoreKMed = allScores[i][0][0:len(summed[0])]\n",
    "            plt.plot(range(1, len(summed[0])+1), siloScoreKMed, label = \"K-Medoids\")\n",
    "            plt.title(\"The maximum silhouette score was achieved at \" + str(np.argmax(np.asarray(summed[0]))+1) + \" clusters for spectral clustering.\")\n",
    "            plt.xlabel(\"Number of clusters\")\n",
    "            plt.ylabel(\"Silhouette Score\")\n",
    "            plt.legend(loc='upper left')\n",
    "            plt.show()\n",
    "            print(\"----------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are going to use tSNE to see how well this technique can learn the distribution of pairwise distance that we create with the counts at depth and dive velocity approach. Here let's look at the distribution of the 2-d embeddings from tSNE. ***NOTE that from the original count matrices, I'm taking many more principle components. *** \n",
    "\n",
    "\n",
    "To run the cells below, first run the first two code blocks at the top of the notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import scipy.spatial.distance\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "\n",
    "pureCounts10PCS = []\n",
    "for i in range(0, 1):\n",
    "    pureCounts10PCS.append(utils.createRepresentation(tags[i], numComponents = 50, probability = False))\n",
    "                                                      \n",
    "\n",
    "        \n",
    "#Adam, the matrix at pureCounts10PCS[0] is like shape (811, numComponents). Whatever the dimension of your embeddings, this is where\n",
    "#you should just plug in the embeddings, and the code below will plot out how the reps look for tSNE. Right now I'm just looking\n",
    "#the reps of a single tag, but you coud just do an extra for-loop over the pureCounts10PCS vector. \n",
    "\n",
    "\n",
    "        \n",
    "perps = [2, 5, 10, 20, 50, 70, 100, 150]\n",
    "distanceMat  = scipy.spatial.distance.squareform(\n",
    "            scipy.spatial.distance.pdist(pureCounts10PCS[0], metric = 'cosine'))\n",
    "for i in range(0, len(perps)):\n",
    "    tsne_2 = TSNE(n_components=2, verbose=1, perplexity=perps[i], n_iter=700, metric = \"precomputed\")\n",
    "    tsne_results = tsne_2.fit_transform(distanceMat)\n",
    "    plt.scatter(x = tsne_results[:, 0],y = tsne_results[:, 1])\n",
    "    plt.title(\"t-SNE embeddings with perplexity \" + str(perps[i]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we want this stuff to look clusterable, which means some clouds of any shape in distinct region. As you can see, there are some embddings that look promising. Now let's look at the 3-d embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import scipy.spatial.distance\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "\n",
    "pureCounts10PCS = []\n",
    "for i in range(0, len(tags)):\n",
    "    pureCounts10PCS.append(utils.createRepresentation(tags[i], numComponents = 50, probability = True))  \n",
    "\n",
    "tsne = list()\n",
    "for i in range(0, len(tags)):\n",
    "    distanceMat  = scipy.spatial.distance.squareform(\n",
    "            scipy.spatial.distance.pdist(pureCounts10PCS[i], metric = 'euclidean'))\n",
    "    tsne_3 = TSNE(n_components=3, verbose=1, perplexity=20, n_iter=700, metric = \"precomputed\")\n",
    "    tsne.append(tsne_3.fit_transform(distanceMat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tsne_results.shape)\n",
    "tsne = [tsne_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(clusterUtils)\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.cluster\n",
    "for i in range(0, len(tsne)): ##each one of these things is a tag\n",
    "    distanceMat = scipy.spatial.distance.squareform(\n",
    "            scipy.spatial.distance.pdist(tsne[i], metric = 'euclidean'))\n",
    "    simMatrix = clusterUtils.simmMatrix(distanceMat, 1.0)\n",
    "    summed = np.zeros((1, 50))\n",
    "    for s in range(0, 5):\n",
    "        tempList= list()\n",
    "        for k in range(2, 52):\n",
    "            spec =  sklearn.cluster.SpectralClustering(n_clusters=k,\n",
    "             assign_labels=\"kmeans\",\n",
    "             random_state=0,\n",
    "            affinity = 'precomputed').fit(simMatrix)\n",
    "            silScore = metrics.silhouette_score(distanceMat, spec.labels_, metric=\"precomputed\", sampleSize = None)\n",
    "            tempList.append(silScore)\n",
    "        summed = summed + np.asarray(tempList)\n",
    "    summed[0] = summed[0] /5\n",
    "    plt.plot(range(1, len(summed[0])+1), summed[0], label = \"Spectral Clustering\")\n",
    "    #siloScoreKMed = allScores[i][0][0:len(summed[0])]\n",
    "    #plt.plot(range(1, len(summed[0])+1), siloScoreKMed, label = \"K-Medoids\")\n",
    "    plt.title(\"The maximum silhouette score was achieved at \" + str(np.argmax(np.asarray(summed[0]))+1) + \" clusters for spectral clustering.\")\n",
    "    plt.xlabel(\"Number of clusters\")\n",
    "    plt.ylabel(\"Silhouette Score\")\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distanceMat = scipy.spatial.distance.squareform(\n",
    "            scipy.spatial.distance.pdist(tsne[i], metric = 'euclidean'))\n",
    "simMatrix = clusterUtils.simmMatrix(distanceMat, 1.0)\n",
    "summed = np.zeros((1, 13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(clusterUtils)\n",
    "import pickle\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.cluster\n",
    "from collections import Counter\n",
    "occs = list()\n",
    "for i in range(0, len(tsne)):\n",
    "    distanceMat = scipy.spatial.distance.squareform(\n",
    "            scipy.spatial.distance.pdist(tsne[i], metric = 'euclidean'))\n",
    "    simMatrix = clusterUtils.simmMatrix(distanceMat, 1.0)\n",
    "    summed = np.zeros((1, 13))\n",
    "    spec =  sklearn.cluster.SpectralClustering(n_clusters=15,\n",
    "                 assign_labels=\"kmeans\",\n",
    "                 random_state=0,\n",
    "                affinity = 'precomputed').fit(simMatrix)\n",
    "    labels = spec.labels_\n",
    "    reorderedLabels = clusterUtils.reorderInverse(labels)\n",
    "    f = open(tags[i].name + 'tSNESmoothed.p',\"wb\")\n",
    "    pickle.dump(labels, f)\n",
    "    f.close()\n",
    "    print(Counter(labels))\n",
    "    coccurences = np.zeros((15, 15))\n",
    "    for window in range(1, 2):\n",
    "        coccurencesTemp = np.zeros((15, 15))\n",
    "        for k in range(0, len(labels) - window):\n",
    "            coccurencesTemp[labels[k],labels[k+window]] += 1/window \n",
    "        coccurences += coccurencesTemp\n",
    "    coccurences = coccurences \n",
    "    occs.append(coccurences)\n",
    "    labelsSplit = np.array_split(labels, 10)\n",
    "    #for i in range(0, len(labelsSplit)):\n",
    "    #    plt.plot(labelsSplit[i])\n",
    "    #    plt.show()\n",
    "        \n",
    "    #listOfClustersExamples = clusterUtils.collectExampleFromClusterAssignments(reorderedLabels, tags[i])\n",
    "    #clusterUtils.plotExamples(listOfClustersExamples, maxNumToPrint = 10)\n",
    "    print(\"______________________________________________________NEW TAG______________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(occs)):\n",
    "    #occs[i] = occs[i] + occs[i].T\n",
    "    plt.imshow(occs[i], cmap = \"Blues\")\n",
    "    plt.colorbar()\n",
    "    plt.title(tags[i].name)\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(tags[0].name + 'tSNE.p',\"wb\")\n",
    "pickle.dump(labels, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arma = pickle.load(open('5111027PAM110P0574TS_arma.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distARMA = scipy.spatial.distance.squareform(\n",
    "            scipy.spatial.distance.pdist(arma , metric = 'cosine'))\n",
    "plt.imshow(distARMA, cmap = \"hot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perps = [5,10,20,40,60,80,100,200]\n",
    "for i in range(0, len(perps)):\n",
    "    tsne_2 = TSNE(n_components=3, verbose=1, perplexity=perps[i], n_iter=700, metric = \"precomputed\")\n",
    "    tsne_results = tsne_2.fit_transform(distARMA )\n",
    "    plt.scatter(x = tsne_results[:, 0],y = tsne_results[:, 1])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "tsne_2 = TSNE(n_components=2, verbose=1, perplexity=20, n_iter=700, metric = \"precomputed\")\n",
    "tsne_results = tsne_2.fit_transform(distARMA )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_2 = TSNE(n_components=2, verbose=1, perplexity=20, n_iter=700, metric = \"precomputed\")\n",
    "tsne_results = tsne_2.fit_transform(distARMA)\n",
    "spec =  sklearn.cluster.SpectralClustering(n_clusters=3,\n",
    "             assign_labels=\"kmeans\",\n",
    "             random_state=0,\n",
    "            affinity = 'nearest_neighbors').fit(tsne_results)\n",
    "labels = spec.labels_ \n",
    "print(len(labels))\n",
    "reorderedLabels = clusterUtils.reorderInverse(labels)\n",
    "listOfClustersExamples = clusterUtils.collectExampleFromClusterAssignments(reorderedLabels, tags[0])\n",
    "clusterUtils.plotExamples(listOfClustersExamples, maxNumToPrint = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "armaList = [arma]\n",
    "for i in range(0, len(armaList)): ##each one of these things is a tag\n",
    "    distanceMat = scipy.spatial.distance.squareform(\n",
    "            scipy.spatial.distance.pdist(armaList[i], metric = 'euclidean'))\n",
    "    simMatrix = clusterUtils.simmMatrix(distanceMat, 1.0)\n",
    "    summed = np.zeros((1, 50))\n",
    "    for s in range(0, 5):\n",
    "        tempList= list()\n",
    "        for k in range(2, 52):\n",
    "            print(\"here\")\n",
    "            spec =  sklearn.cluster.SpectralClustering(n_clusters=k,\n",
    "             assign_labels=\"kmeans\",\n",
    "             random_state=0,\n",
    "            affinity = 'precomputed').fit(simMatrix)\n",
    "            silScore = metrics.silhouette_score(distanceMat, spec.labels_, metric=\"precomputed\", sampleSize = None)\n",
    "            tempList.append(silScore)\n",
    "        summed = summed + np.asarray(tempList)\n",
    "    summed[0] = summed[0] /5\n",
    "    plt.plot(range(1, len(summed[0])+1), summed[0], label = \"Spectral Clustering\")\n",
    "    #siloScoreKMed = allScores[i][0][0:len(summed[0])]\n",
    "    #plt.plot(range(1, len(summed[0])+1), siloScoreKMed, label = \"K-Medoids\")\n",
    "    plt.title(\"The maximum silhouette score was achieved at \" + str(np.argmax(np.asarray(summed[0]))+1) + \" clusters for spectral clustering.\")\n",
    "    plt.xlabel(\"Number of clusters\")\n",
    "    plt.ylabel(\"Silhouette Score\")\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, as a final step, we are going to just look at some simple representations of the dives: max depth, time as certain depths, and the average depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(tags)):\n",
    "    utils.createSimpleRepresentations(tags[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "tempSimpleReps = tags[0].simpleReps\n",
    "normalized = (tempSimpleReps - tempSimpleReps.mean(axis=0)) / (tempSimpleReps.std(axis=0) + .00001)\n",
    "pca = PCA(n_components=20)\n",
    "pca.fit(normalized)\n",
    "myData = pca.fit_transform(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perps = [2, 5, 10, 20, 50]\n",
    "distanceMat  = scipy.spatial.distance.squareform(\n",
    "            scipy.spatial.distance.pdist(myData, metric = 'euclidean'))\n",
    "for i in range(0, len(perps)):\n",
    "    tsne_2 = TSNE(n_components=2, verbose=1, perplexity=perps[i], n_iter=700, metric = \"precomputed\")\n",
    "    tsne_results = tsne_2.fit_transform(distanceMat)\n",
    "    plt.scatter(x = tsne_results[:, 0],y = tsne_results[:, 1])\n",
    "    plt.title(\"t-SNE embeddings with perplexity = \" + str(10))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_simple = tsne_2 = TSNE(n_components=2, verbose=1, perplexity=10, n_iter=700, metric = \"precomputed\")\n",
    "tsne_results_simple = tsne_2.fit_transform(distanceMat)\n",
    "print(tsne_results.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "armaList = [tsne_results_simple]\n",
    "for i in range(0, len(armaList)): ##each one of these things is a tag\n",
    "    distanceMat = scipy.spatial.distance.squareform(\n",
    "            scipy.spatial.distance.pdist(armaList[i], metric = 'euclidean'))\n",
    "    simMatrix = clusterUtils.simmMatrix(distanceMat, 1.0)\n",
    "    summed = np.zeros((1, 50))\n",
    "    for s in range(0, 5):\n",
    "        tempList= list()\n",
    "        for k in range(2, 52):\n",
    "            print(\"here\")\n",
    "            spec =  sklearn.cluster.SpectralClustering(n_clusters=k,\n",
    "             assign_labels=\"kmeans\",\n",
    "             random_state=0,\n",
    "            affinity = 'precomputed').fit(simMatrix)\n",
    "            silScore = metrics.silhouette_score(distanceMat, spec.labels_, metric=\"precomputed\", sampleSize = None)\n",
    "            tempList.append(silScore)\n",
    "        summed = summed + np.asarray(tempList)\n",
    "    summed[0] = summed[0] /5\n",
    "    plt.plot(range(1, len(summed[0])+1), summed[0], label = \"Spectral Clustering\")\n",
    "    #siloScoreKMed = allScores[i][0][0:len(summed[0])]\n",
    "    #plt.plot(range(1, len(summed[0])+1), siloScoreKMed, label = \"K-Medoids\")\n",
    "    plt.title(\"The maximum silhouette score was achieved at \" + str(np.argmax(np.asarray(summed[0]))+1) + \" clusters for spectral clustering.\")\n",
    "    plt.xlabel(\"Number of clusters\")\n",
    "    plt.ylabel(\"Silhouette Score\")\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simMatrix = clusterUtils.simmMatrix(distanceMat, 1.0)\n",
    "spec =  sklearn.cluster.SpectralClustering(n_clusters=10,\n",
    "             assign_labels=\"kmeans\",\n",
    "             random_state=0,\n",
    "            affinity = 'precomputed').fit(simMatrix)\n",
    "labels = spec.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reorderedLabels = clusterUtils.reorderInverse(labels)\n",
    "listOfClustersExamples = clusterUtils.collectExampleFromClusterAssignments(reorderedLabels, tags[0])\n",
    "clusterUtils.plotExamples(listOfClustersExamples, maxNumToPrint = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = simpleSimpleReps[:, 0],y = simpleSimpleReps[:, 2])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(627,)\n",
      "(627,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Lengths must match to compare",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b3b907483d51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtagStruct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetThermocline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/CS221/project/Code/tagStruct.py\u001b[0m in \u001b[0;36mgetThermocline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpiecewise_linear_regression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMixedLayerRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpsi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CS221/project/Code/piecewise_linear_regression.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__find_psi__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CS221/project/Code/piecewise_linear_regression.py\u001b[0m in \u001b[0;36m__find_psi__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;31m# Fitting procedure from [1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__Us__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__Vs__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CS221/project/Code/piecewise_linear_regression.py\u001b[0m in \u001b[0;36m__Vs__\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpsi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__initialize_psi__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m   1251\u001b[0m             \u001b[0;31m# as it will broadcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1253\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Lengths must match to compare'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m             \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Lengths must match to compare"
     ]
    }
   ],
   "source": [
    "importlib.reload(tagStruct)\n",
    "for tag in tags:\n",
    "    tag.getThermocline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
